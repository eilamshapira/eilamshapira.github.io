---
---

@misc{shapira2024gleeunifiedframeworkbenchmark,
      pdf={https://arxiv.org/pdf/2410.05254.pdf},
      bibtex_show={true},
      abstract={Large Language Models (LLMs) show significant potential in economic and
strategic interactions, where communication via natural language is often prevalent. This raises key questions: Do LLMs behave rationally? Can they mimic
human behavior? Do they tend to reach an efficient and fair outcome? What is
the role of natural language in the strategic interaction? How do characteristics
of the economic environment influence these dynamics? These questions become
crucial concerning the economic and societal implications of integrating LLMbased agents into real-world data-driven systems, such as online retail platforms
and recommender systems. While the ML community has been exploring the potential of LLMs in such multi-agent setups, varying assumptions, design choices
and evaluation criteria across studies make it difficult to draw robust and meaningful conclusions. To address this, we introduce a benchmark for standardizing
research on two-player, sequential, language-based games. Inspired by the economic literature, we define three base families of games with consistent parameterization, degrees of freedom and economic measures to evaluate agentsâ€™ performance (self-gain), as well as the game outcome (efficiency and fairness). We
develop an open-source framework for interaction simulation and analysis, and
utilize it to collect a dataset of LLM vs. LLM interactions across numerous game
configurations and an additional dataset of human vs. LLM interactions. Through
extensive experimentation, we demonstrate how our framework and dataset can
be used to: (i) compare the behavior of LLM-based agents to human players in
various economic contexts; (ii) evaluate agents in both individual and collective
performance measures; and (iii) quantify the effect of the economic characteristics of the environments on the behavior of agents. We believe that our framework
can contribute to the growing intersection of LLMs, ML, and economics, and we
encourage researchers to explore it further and build on its foundation.},
      title={GLEE: A Unified Framework and Benchmark for Language-based Economic Environments},
      author={Eilam Shapira and Omer Madmon and Itamar Reinman and Samuel Joseph Amouyal and Roi Reichart and Moshe Tennenholtz},
      year={2024},
      eprint={2410.05254},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2410.05254},
      selected={true},
      code={https://github.com/eilamshapira/GLEE},
}

@article{shapira2024can,
  abstract={Human choice prediction in economic contexts
is crucial for applications in marketing, finance,
public policy, and more. This task, however,
is often constrained by the difficulties in acquiring human choice data. With most experimental economics studies focusing on simple
choice settings, the AI community has explored
whether LLMs can substitute for humans in
these predictions and examined more complex
experimental economics settings. However, a
key question remains: can LLMs generate training data for human choice prediction? We explore this in language-based persuasion games,
a complex economic setting involving natural language in strategic interactions. Our experiments show that models trained on LLMgenerated data can effectively predict human
behavior in these games and even outperform
models trained on actual human data.},
  bibtex_show={true},
  pdf={https://arxiv.org/pdf/2401.17435.pdf},
  title={Can Large Language Models Replace Economic Choice Prediction Labs? The Case of Language-based Persuasion Games},
  author={Shapira, Eilam and Madmon, Omer and Reichart, Roi and Tennenholtz, Moshe},
  journal={arXiv preprint arXiv:2401.17435},
  year={2024},
  selected={true},
}

@misc{amosy2024text2modeltextbasedmodelinduction,
      bibtex_show={true},
      abstract={We address the challenge of building task-agnostic classifiers using only text descriptions, demonstrating a unified approach to image classification, 3D point cloud classification, and action recognition from scenes. Unlike approaches that learn a fixed representation of the output classes, we generate at inference time a model tailored to a query classification task. To generate task-based zero-shot classifiers, we train a hypernetwork that receives class descriptions and outputs a multi-class model. The hypernetwork is designed to be equivariant with respect to the set of descriptions and the classification layer, thus obeying the symmetries of the problem and improving generalization. Our approach generates non-linear classifiers, handles rich textual descriptions, and may be adapted to produce lightweight models efficient enough for on-device applications. We evaluate this approach in a series of zero-shot classification tasks, for image, point-cloud, and action recognition, using a range of text descriptions: From single words to rich descriptions. Our results demonstrate strong improvements over previous approaches, showing that zero-shot learning can be applied with little training data. Furthermore, we conduct an analysis with foundational vision and language models, demonstrating that they struggle to generalize when describing what attributes the class lacks.},
      pdf={https://arxiv.org/pdf/2210.15182.pdf},
      title={Text2Model: Text-based Model Induction for Zero-shot Image Classification},
      author={Ohad Amosy and Tomer Volk and Eilam Shapira and Eyal Ben-David and Roi Reichart and Gal Chechik},
      year={2024},
      eprint={2210.15182},
      archivePrefix={arXiv},
      primaryClass={cs.CV},
      url={https://arxiv.org/abs/2210.15182},
}


@article{shapira2023human,
abstract={Recent advances in Large Language Models (LLMs) have spurred interest in designing LLM-based agents for tasks that involve interaction with human and artificial agents. This paper addresses a key aspect in the design of such agents: Predicting human decision in off-policy evaluation (OPE), focusing on language-based persuasion games, where the agent's goal is to influence its partner's decisions through verbal messages. Using a dedicated application, we collected a dataset of 87K decisions from humans playing a repeated decision-making game with artificial agents. Our approach involves training a model on human interactions with one agents subset to predict decisions when interacting with another. To enhance off-policy performance, we propose a simulation technique involving interactions across the entire agent space and simulated decision makers. Our learning strategy yields significant OPE gains, e.g., improving prediction accuracy in the top 15% challenging cases by 7.1%. Our code and the large dataset we collected and generated are submitted as supplementary material and publicly available in our GitHub repository},
  bibtex_show={true},
  pdf={https://arxiv.org/pdf/2305.10361.pdf},
  title={Human Choice Prediction in Language-based Persuasion Games: Simulation-based Off-Policy Evaluation},
  author={Shapira, Eilam and Apel, Reut and Tennenholtz, Moshe and Reichart, Roi},
  journal={arXiv preprint arXiv:2305.10361},
  year={2023},
  selected={true},
  code={https://github.com/eilamshapira/HumanChoicePrediction},
}

